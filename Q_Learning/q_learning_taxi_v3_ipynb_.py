# -*- coding: utf-8 -*-
"""Q_Learning_Taxi_v3_ipynb_.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EEJQ3tQR1P2YtHUwxTb0jL6qg7s3xME0
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np

import gym

import matplotlib.pyplot as plt
# %matplotlib inline

env = gym.make('Taxi-v3')

NUM_STATES = env.observation_space.n
NUM_ACTIONS = env.action_space.n

print('States: {}'.format(NUM_STATES))
print('Actions: {}'.format(NUM_ACTIONS))

lr = 0.8 
gamma = 0.6 

NUM_EPISODES = 500 
MAX_STEPS = 100

pathLenList = []
totalRewardList = [] 

Q = np.random.rand(NUM_STATES, NUM_ACTIONS)

for i in range(NUM_EPISODES):
    
    s = env.reset()

    penalties = 0
    totalReward = 0
    step = 0
    done = False

    while not done:
        
        a = np.argmax(Q[s,:])
        
        s1, r, done, _ = env.step(a)
        
        if r == -10:
            penalties += 1

        if done:
            Q_target = r
        else:
            Q_target = r + gamma * np.max(Q[s1,:])
            
        Q[s,a] = (1-lr) * Q[s,a] + lr * Q_target
        
        totalReward += r
        s = s1
        
        if done:
            break
            
    pathLenList.append(step)
    totalRewardList.append(totalReward)
    print('Episode {}: Total reward = {}'.format(i, totalReward))

plt.plot(totalRewardList)
plt.grid()

"""### Запуск симуляции"""

totalReward = 0
s = env.reset()

for _ in range(100):
    env.render()
    a = np.argmax(Q[s,:])
    s, r, done, _ = env.step(a)
    totalReward += r
    if done:
        env.render()        
        break

env.close()
print('Total reward = {}'.format(totalReward))