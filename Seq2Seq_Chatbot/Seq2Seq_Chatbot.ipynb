{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_Seq2Seq_Chatbot.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV7krOYLLIqF",
        "outputId": "39555243-2520-4af8-a4c7-242bb91a8ae6"
      },
      "source": [
        "import codecs\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2UTcFsUhYYp"
      },
      "source": [
        "INPUT_LENGTH = 10\n",
        "OUTPUT_LENGTH = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlB3BSZhhlM3"
      },
      "source": [
        "lines = open('/content/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
        "conv_lines = open('/content/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kj-oWFthwj-"
      },
      "source": [
        "# создадим словарь, в котором соответсвующей строчке будет соответсвовать ее ID\n",
        "\n",
        "id2line = {}\n",
        "for line in lines:\n",
        "    _line = line.split(' +++$+++ ')\n",
        "    if len(_line) == 5:\n",
        "        id2line[_line[0]] = _line[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GKWzMnIhypS"
      },
      "source": [
        "# создадим список диалогов\n",
        "\n",
        "convs = []\n",
        "for line in conv_lines[:-1]:\n",
        "    _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
        "    convs.append(_line.split(','))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUtU1AlCh4o2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ecd61f-50de-41b3-eea0-6b4054e2db68"
      },
      "source": [
        "# отсортируем предложения на вопрос/ответ\n",
        "\n",
        "questions = []\n",
        "answers = []\n",
        "for conv in convs:\n",
        "    for i in range(len(conv)-1):\n",
        "        questions.append(id2line[conv[i]])\n",
        "        answers.append(id2line[conv[i+1]])\n",
        "        \n",
        "print(len(questions))\n",
        "print(len(answers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "221616\n",
            "221616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phG5AJPUh4v7"
      },
      "source": [
        "# создадим функцию для очистки текста\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|]\", \"\", text)\n",
        "    text = \" \".join(text.split())\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxadRMzqh46l"
      },
      "source": [
        "# очистим текст\n",
        "\n",
        "clean_questions = []\n",
        "for question in questions:\n",
        "    clean_questions.append(clean_text(question))\n",
        "clean_answers = []    \n",
        "for answer in answers:\n",
        "    clean_answers.append(clean_text(answer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBBLtQqiiC8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e439ef-db50-40f7-b465-9a665b128d3b"
      },
      "source": [
        "# найдем длины последовательностей\n",
        "\n",
        "lengths = []\n",
        "\n",
        "for question in clean_questions:\n",
        "    lengths.append(len(question.split()))\n",
        "for answer in clean_answers:\n",
        "    lengths.append(len(answer.split()))\n",
        "\n",
        "lengths = pd.DataFrame(lengths, columns=['counts'])\n",
        "\n",
        "print(np.percentile(lengths, 80))\n",
        "print(np.percentile(lengths, 85))\n",
        "print(np.percentile(lengths, 90))\n",
        "print(np.percentile(lengths, 95))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16.0\n",
            "19.0\n",
            "24.0\n",
            "32.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5xbsoroiDGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e099f88-4f60-4699-b4c1-da6de32fb726"
      },
      "source": [
        "# удалим вопросы и ответы длина которых больше 2 и меньше 16\n",
        "\n",
        "min_line_length = 2\n",
        "max_line_length = 16\n",
        "\n",
        "short_questions_temp = []\n",
        "short_answers_temp = []\n",
        "\n",
        "for i, question in enumerate(clean_questions):\n",
        "    if len(question.split()) >= min_line_length and len(question.split()) <= max_line_length:\n",
        "        short_questions_temp.append(question)\n",
        "        short_answers_temp.append(clean_answers[i])\n",
        "        \n",
        "short_questions = []\n",
        "short_answers = []\n",
        "\n",
        "for i, answer in enumerate(short_answers_temp):\n",
        "    if len(answer.split()) >= min_line_length and len(answer.split()) <= max_line_length:\n",
        "        short_answers.append(answer)\n",
        "        short_questions.append(short_questions_temp[i])\n",
        "        \n",
        "print(len(short_questions))\n",
        "print(len(short_answers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118928\n",
            "118928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyMbW-HTiDb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e14b916-2631-49e8-a593-44a0943187b7"
      },
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "num_samples = 20000  # количество семплов для тренировки\n",
        "short_questions = short_questions[:num_samples]\n",
        "short_answers = short_answers[:num_samples]\n",
        "\n",
        "# получим токены для вопросов/ответов\n",
        "short_questions_tok = [nltk.word_tokenize(sent) for sent in short_questions]\n",
        "short_answers_tok = [nltk.word_tokenize(sent) for sent in short_answers]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj762pxAiDjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145131bc-eab5-4a87-8170-ecdabcc17b67"
      },
      "source": [
        "# сделаем разбивку данных на тренировочные и валидационные\n",
        "\n",
        "data_size = len(short_questions_tok)\n",
        "\n",
        "training_input  = short_questions_tok[:round(data_size*(80/100))]\n",
        "training_input  = [tr_input[::-1] for tr_input in training_input] \n",
        "training_output = short_answers_tok[:round(data_size*(80/100))]\n",
        "\n",
        "validation_input = short_questions_tok[round(data_size*(80/100)):]\n",
        "validation_input  = [val_input[::-1] for val_input in validation_input] \n",
        "validation_output = short_answers_tok[round(data_size*(80/100)):]\n",
        "\n",
        "print('training size', len(training_input))\n",
        "print('validation size', len(validation_input))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training size 16000\n",
            "validation size 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i74mhoKaiDyK"
      },
      "source": [
        "# создадим словарь с частотой использования слов\n",
        "\n",
        "vocab = {}\n",
        "for question in short_questions_tok:\n",
        "    for word in question:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = 1\n",
        "        else:\n",
        "            vocab[word] += 1\n",
        "\n",
        "for answer in short_answers_tok:\n",
        "    for word in answer:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = 1\n",
        "        else:\n",
        "            vocab[word] += 1  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77lgtekuiU8w"
      },
      "source": [
        "# удалим редко используемые слова из словаря\n",
        "\n",
        "threshold = 15\n",
        "count = 0\n",
        "for k,v in vocab.items():\n",
        "    if v >= threshold:\n",
        "        count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twr31XnFiVGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f177f5-3806-4cdd-d5db-5356f8dbb7e5"
      },
      "source": [
        "print(\"Размер словаря:\", len(vocab))\n",
        "print(\"Количество используемых слов:\", count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размер словаря: 12352\n",
            "Количество используемых слов: 1310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHthTeO9iVON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78cfe46e-63a0-44cd-c6c7-9b1cfdd7256a"
      },
      "source": [
        "# создадим словарь, где каждому слову соответстует свой номер\n",
        "\n",
        "WORD_CODE_START = 1\n",
        "WORD_CODE_PADDING = 0\n",
        "\n",
        "\n",
        "word_num  = 2\n",
        "encoding = {}\n",
        "decoding = {1: 'START'}\n",
        "for word, count in vocab.items():\n",
        "    if count >= threshold:\n",
        "        encoding[word] = word_num \n",
        "        decoding[word_num ] = word\n",
        "        word_num += 1\n",
        "\n",
        "print(\"Количество используемых токенов:\", word_num)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество используемых токенов: 1312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rZ5a_CSiVW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3075bef-3492-4f6b-dd88-67dbb198dd9f"
      },
      "source": [
        "# используем <UNK> токен для слов вне словаря\n",
        "\n",
        "decoding[len(encoding)+2] = '<UNK>'\n",
        "encoding['<UNK>'] = len(encoding)+2\n",
        "\n",
        "dict_size = word_num+1\n",
        "dict_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1313"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1b5hwHPiD6y"
      },
      "source": [
        "# создадим функцию для приведения строк к единому вектору\n",
        "\n",
        "def transform(encoding, data, vector_size=10):\n",
        "\n",
        "    transformed_data = np.zeros(shape=(len(data), vector_size))\n",
        "    for i in range(len(data)):\n",
        "        for j in range(min(len(data[i]), vector_size)):\n",
        "            try:\n",
        "                transformed_data[i][j] = encoding[data[i][j]]\n",
        "            except:\n",
        "                transformed_data[i][j] = encoding['<UNK>']\n",
        "    return transformed_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsnDT4bDijaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d8b0c55-92d1-4b0c-e378-a2879dad90d8"
      },
      "source": [
        "# отформатируем тренировочные данные\n",
        "\n",
        "encoded_training_input = transform(\n",
        "    encoding, training_input, vector_size=INPUT_LENGTH)\n",
        "encoded_training_output = transform(\n",
        "    encoding, training_output, vector_size=OUTPUT_LENGTH)\n",
        "\n",
        "print('encoded_training_input', encoded_training_input.shape)\n",
        "print('encoded_training_output', encoded_training_output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoded_training_input (16000, 10)\n",
            "encoded_training_output (16000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR0PGpZTijjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e0023f-1e1f-4a73-ead5-9a95bff2d3d4"
      },
      "source": [
        "# отформатируем валидационные данные\n",
        "\n",
        "encoded_validation_input = transform(\n",
        "    encoding, validation_input, vector_size=INPUT_LENGTH)\n",
        "encoded_validation_output = transform(\n",
        "    encoding, validation_output, vector_size=OUTPUT_LENGTH)\n",
        "\n",
        "print('encoded_validation_input', encoded_validation_input.shape)\n",
        "print('encoded_validation_output', encoded_validation_output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoded_validation_input (4000, 10)\n",
            "encoded_validation_output (4000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACWTc2IKij24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b8e0bb-792f-4a8f-f023-2eb48866a8b9"
      },
      "source": [
        "# создадим модель encoder/decoder\n",
        "\n",
        "INPUT_LENGTH = 10\n",
        "OUTPUT_LENGTH = 10\n",
        "\n",
        "encoder_input = tf.keras.layers.Input(shape=(INPUT_LENGTH,))\n",
        "decoder_input = tf.keras.layers.Input(shape=(OUTPUT_LENGTH,))\n",
        "\n",
        "encoder = tf.keras.layers.Embedding(dict_size, 128, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
        "encoder = tf.keras.layers.LSTM(512, unroll=True, return_sequences=True)(encoder)\n",
        "encoder_last = encoder[:,-1,:]\n",
        "\n",
        "print('encoder', encoder)\n",
        "print('encoder_last', encoder_last)\n",
        "\n",
        "decoder = tf.keras.layers.Embedding(dict_size, 128, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
        "decoder = tf.keras.layers.LSTM(512, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])\n",
        "\n",
        "print('decoder', decoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "encoder KerasTensor(type_spec=TensorSpec(shape=(None, 10, 512), dtype=tf.float32, name=None), name='lstm/transpose_2:0', description=\"created by layer 'lstm'\")\n",
            "encoder_last KerasTensor(type_spec=TensorSpec(shape=(None, 512), dtype=tf.float32, name=None), name='tf.__operators__.getitem/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem'\")\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "decoder KerasTensor(type_spec=TensorSpec(shape=(None, 10, 512), dtype=tf.float32, name=None), name='lstm_1/transpose_2:0', description=\"created by layer 'lstm_1'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIWa-5VJkmXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "463a2430-138d-44e0-c361-24ce4e560957"
      },
      "source": [
        "# реализуем механизм attention\n",
        "\n",
        "from keras.layers import Activation, dot, concatenate, TimeDistributed, Dense\n",
        "\n",
        "attention = dot([decoder, encoder], axes=[2, 2])\n",
        "attention = Activation('softmax', name='attention')(attention)\n",
        "print('attention', attention)\n",
        "\n",
        "context = dot([attention, encoder], axes=[2,1])\n",
        "print('context', context)\n",
        "\n",
        "decoder_combined_context = concatenate([context, decoder])\n",
        "print('decoder_combined_context', decoder_combined_context)\n",
        "\n",
        "output = TimeDistributed(Dense(512, activation=\"tanh\"))(decoder_combined_context)\n",
        "output = TimeDistributed(Dense(dict_size, activation=\"softmax\"))(output)\n",
        "print('output', output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention KerasTensor(type_spec=TensorSpec(shape=(None, 10, 10), dtype=tf.float32, name=None), name='attention/truediv:0', description=\"created by layer 'attention'\")\n",
            "context KerasTensor(type_spec=TensorSpec(shape=(None, 10, 512), dtype=tf.float32, name=None), name='dot_1/MatMul:0', description=\"created by layer 'dot_1'\")\n",
            "decoder_combined_context KerasTensor(type_spec=TensorSpec(shape=(None, 10, 1024), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n",
            "output KerasTensor(type_spec=TensorSpec(shape=(None, 10, 1313), dtype=tf.float32, name=None), name='time_distributed_1/Reshape_1:0', description=\"created by layer 'time_distributed_1'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXIE1mYak0z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cf2adf-9c38-48de-c8a0-fcd8024e32ab"
      },
      "source": [
        "from keras.models import Model, load_model\n",
        "\n",
        "model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 10, 128)      168064      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 10, 512)      1312768     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 10, 128)      168064      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None, 512)          0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 10, 512)      1312768     embedding_1[0][0]                \n",
            "                                                                 tf.__operators__.getitem[0][0]   \n",
            "                                                                 tf.__operators__.getitem[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 10, 10)       0           lstm_1[0][0]                     \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "attention (Activation)          (None, 10, 10)       0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 10, 512)      0           attention[0][0]                  \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 10, 1024)     0           dot_1[0][0]                      \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 10, 512)      524800      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 10, 1313)     673569      time_distributed[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 4,160,033\n",
            "Trainable params: 4,160,033\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WsE-8G5lCCh"
      },
      "source": [
        "# подготовим входы/выходы для encoder/decoder\n",
        "\n",
        "training_encoder_input = encoded_training_input\n",
        "training_decoder_input = np.zeros_like(encoded_training_output)\n",
        "training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n",
        "training_decoder_input[:, 0] = WORD_CODE_START\n",
        "training_decoder_output = np.eye(dict_size)[encoded_training_output.astype('int')]\n",
        "\n",
        "validation_encoder_input = encoded_validation_input\n",
        "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
        "validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n",
        "validation_decoder_input[:, 0] = WORD_CODE_START\n",
        "validation_decoder_output = np.eye(dict_size)[encoded_validation_output.astype('int')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTn3Ll1glMTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbbcc86e-260d-4389-867a-71e90a47aadf"
      },
      "source": [
        "model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
        "          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
        "          batch_size=64, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - 11s 21ms/step - loss: 0.0043 - val_loss: 0.0033\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0033 - val_loss: 0.0031\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0031 - val_loss: 0.0029\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0020 - val_loss: 0.0030\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0018 - val_loss: 0.0030\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0017 - val_loss: 0.0031\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0015 - val_loss: 0.0033\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0014 - val_loss: 0.0033\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0013 - val_loss: 0.0034\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0012 - val_loss: 0.0035\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0011 - val_loss: 0.0036\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 8.9514e-04 - val_loss: 0.0038\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 8.0515e-04 - val_loss: 0.0040\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 7.1203e-04 - val_loss: 0.0041\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 6.3149e-04 - val_loss: 0.0042\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 5.5543e-04 - val_loss: 0.0043\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 4.8670e-04 - val_loss: 0.0044\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 4.1741e-04 - val_loss: 0.0045\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 3.6204e-04 - val_loss: 0.0046\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 3.1162e-04 - val_loss: 0.0047\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 2.6445e-04 - val_loss: 0.0048\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 2.2491e-04 - val_loss: 0.0049\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 2.0527e-04 - val_loss: 0.0050\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 1.9606e-04 - val_loss: 0.0051\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 1.9514e-04 - val_loss: 0.0051\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 1.7964e-04 - val_loss: 0.0052\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 1.4998e-04 - val_loss: 0.0052\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 1.1064e-04 - val_loss: 0.0053\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 8.7207e-05 - val_loss: 0.0054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff5e0221e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TT64VuhlMhk"
      },
      "source": [
        "# создадим функции для предсказания и декодирования векторов в текст\n",
        "\n",
        "def prediction(raw_input):\n",
        "    clean_input = clean_text(raw_input)\n",
        "    input_tok = [nltk.word_tokenize(clean_input)]\n",
        "    input_tok = [input_tok[0][::-1]]  \n",
        "    encoder_input = transform(encoding, input_tok, 10)\n",
        "    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n",
        "    decoder_input[:,0] = WORD_CODE_START\n",
        "    for i in range(1, OUTPUT_LENGTH):\n",
        "        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
        "        decoder_input[:,i] = output[:,i]\n",
        "    return output\n",
        "\n",
        "def decode(decoding, vector):\n",
        "    text = ''\n",
        "    for i in vector:\n",
        "        if i == 0:\n",
        "            break\n",
        "        text += ' '\n",
        "        text += decoding[i]\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge0bWwdXTQLu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ad6ba6d8-796c-47d0-a13e-e4fed4604632"
      },
      "source": [
        "# проверим ответ модели на рандомном тексте\n",
        "\n",
        "text_random = 'how are you?'\n",
        "\n",
        "output2 = prediction(text_random)\n",
        "decode(decoding, output2[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' been better . i read about that is been been'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}
